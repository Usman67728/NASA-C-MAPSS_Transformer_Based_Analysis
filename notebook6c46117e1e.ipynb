{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10901458,"sourceType":"datasetVersion","datasetId":6775314},{"sourceId":166218,"sourceType":"modelInstanceVersion","modelInstanceId":141432,"modelId":164048}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:12:49.784455Z","iopub.execute_input":"2025-10-12T09:12:49.784657Z","iopub.status.idle":"2025-10-12T09:12:51.516297Z","shell.execute_reply.started":"2025-10-12T09:12:49.78464Z","shell.execute_reply":"2025-10-12T09:12:51.515671Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:12:51.517035Z","iopub.execute_input":"2025-10-12T09:12:51.517431Z","iopub.status.idle":"2025-10-12T09:12:56.772215Z","shell.execute_reply.started":"2025-10-12T09:12:51.517412Z","shell.execute_reply":"2025-10-12T09:12:56.771377Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Introduction\nModern aircraft engines are equipped with hundreds of sensors monitoring temperature, pressure, vibration, and other critical parameters. Predicting Remaining Useful Life (RUL) is essential for:\n* Preventing catastrophic engine failures\n* Optimizing maintenance schedules\n* Reducing downtime and operational costs\n  \nThis notebook demonstrates a hybrid CNN + Transformer architecture to predict RUL from engine sensor time-series data.\\\nAdvantages of this approach over traditional models like LSTM/GRU:\n* Transformer layer: Captures long-range dependencies across cycles, which LSTMs may struggle with for long sequences.\n* Asymmetric loss function: Penalizes overestimation of RUL (critical for safety-critical applications).\n* Sensor-to-subsystem mapping: Helps interpret model decisions and provide actionable maintenance recommendations.","metadata":{}},{"cell_type":"markdown","source":"# Load & Preprocess (train / test)\nWe use the CMAPSS (Commercial Modular Aero-Propulsion System Simulation) dataset:\\\nFeatures:\n* 3 operating settings (op_setting_1,2,3)\n* 21 sensors monitoring engine subsystems such as Fan, LPC, HPC, Combustion Chamber, HPT\n* Engine cycles: Sequential time steps for each engine","metadata":{}},{"cell_type":"code","source":"# 1. Paths and sensor->subsystem mapping\nTRAIN_PATH = '/kaggle/input/cmapss-jet-engine-simulated-data/train_FD001.txt'\nTEST_PATH  = '/kaggle/input/cmapss-jet-engine-simulated-data/test_FD001.txt'\nTRUTH_PATH = '/kaggle/input/cmapss-jet-engine-simulated-data/RUL_FD001.txt'\n\n# Sensor to subsystem mapping provided by user\nSENSOR_TO_SUBSYSTEM = {\n    'sensor_1': ['Fan inlet temperature', 'Overall Inlet'],\n    'sensor_2': ['Fan inlet pressure (psia)', 'Overall Inlet'],\n    'sensor_3': ['HPC outlet pressure (psia)','High-Pressure Compressor (HPC)'],\n    'sensor_4': ['HPT outlet temperature','High-Pressure Turbine (HPT)'],\n    'sensor_5': ['LPC outlet temperature','Low-Pressure Compressor (LPC)'],\n    'sensor_6': ['Fan speed rpm','Fan'],\n    'sensor_7': ['Fan inlet pressure (psia)', 'Overall Inlet'],\n    'sensor_8': ['HPC outlet static pressure (psia)','High-Pressure Compressor (HPC)'],\n    'sensor_9': ['Corrected fan speed (rpm)','Fan'],\n    'sensor_10': ['Ratio of pressure (bypass)Fan', 'Overall'],\n    'sensor_11': ['Fuel flow (pph)','Combustion Chamber'],\n    'sensor_12': ['LPC outlet temperature (corrected)','Low-Pressure Compressor (LPC)'],\n    'sensor_13': ['HPT outlet temperature (corrected)','High-Pressure Turbine (HPT)'],\n    'sensor_14': ['Physical fan speed (rpm)','Fan'],\n    'sensor_15': ['Physical core engine speed (rpm)','High-Pressure Compressor (HPC) and High-Pressure Turbine (HPT)'],\n    'sensor_16': ['Bleed air (units)','Overall Engine System'],\n    'sensor_17': ['Fuel-air ratio','Combustion Chamber'],\n    'sensor_18': ['Thrust-specific fuel consumption (TSFC)','Overall Engine System'],\n    'sensor_19': ['Total temperature at LPC exit','Low-Pressure Compressor (LPC)'],\n    'sensor_20': ['Engine pressure ratio','Overall Engine System'],\n    'sensor_21': ['Total temperature at HPT exit ','High-Pressure Turbine (HPT)']\n}\n\n# 2. Load & preprocess data (features scaled; RUL kept in cycles)\ntrain = pd.read_csv(TRAIN_PATH, sep=' ', header=None)\ntrain.drop([26,27], axis=1, inplace=True)\ncols = ['engine_id','cycle'] + [f'op_setting_{i+1}' for i in range(3)] + [f'sensor_{i+1}' for i in range(21)]\ntrain.columns = cols\n\nrul_df = train.groupby('engine_id')['cycle'].max().reset_index()\nrul_df.columns = ['engine_id', 'max_cycle']\ntrain = train.merge(rul_df, on='engine_id')\ntrain['RUL'] = train['max_cycle'] - train['cycle']\ntrain.drop('max_cycle', axis=1, inplace=True)\n\nMAX_RUL = 125\ntrain['RUL'] = train['RUL'].clip(upper=MAX_RUL)\n\nfeature_cols = train.columns[2:-1]\nscaler = MinMaxScaler()\ntrain[feature_cols] = scaler.fit_transform(train[feature_cols])\n\n# test & truth\ntest = pd.read_csv(TEST_PATH, sep=' ', header=None)\ntest.drop([26,27], axis=1, inplace=True)\ntest.columns = cols\n\ntruth = pd.read_csv(TRUTH_PATH, header=None)\ntruth.columns = ['RUL']\n\n# scale test\ntest[feature_cols] = scaler.transform(test[feature_cols])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:12:56.773977Z","iopub.execute_input":"2025-10-12T09:12:56.774381Z","iopub.status.idle":"2025-10-12T09:12:57.025003Z","shell.execute_reply.started":"2025-10-12T09:12:56.774362Z","shell.execute_reply":"2025-10-12T09:12:57.024223Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sensor trends for all sensors with subsystem color coding\nVisualize engine health trends for individual sensors mapped to subsystems:\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set(style=\"whitegrid\", font_scale=1.0)\n\n# Select a sample engine\nsample_engine_id = train['engine_id'].unique()[0]\nsample_engine_data = train[train['engine_id'] == sample_engine_id]\n\n# Prepare color map for subsystems\nsubsystems = list(set([sub for subs in SENSOR_TO_SUBSYSTEM.values() for sub in subs]))\ncolors = sns.color_palette(\"tab20\", len(subsystems))\nsubsystem_color_map = {sub: colors[i] for i, sub in enumerate(subsystems)}\n\n# Plot each sensor in a grid\nnum_sensors = len(feature_cols)\ncols = 3\nrows = (num_sensors + cols - 1) // cols\n\nfig, axes = plt.subplots(rows, cols, figsize=(15, rows*3), sharex=True)\naxes = axes.flatten()\n\nfor i, sensor in enumerate(feature_cols):\n    subs = SENSOR_TO_SUBSYSTEM.get(sensor, ['Unknown'])\n    subsystem_color_map['Unknown'] = 'grey'\n    color = subsystem_color_map[subs[0]]  # take first subsystem for color\n    axes[i].plot(sample_engine_data['cycle'], sample_engine_data[sensor], color=color)\n    axes[i].set_title(f\"{sensor} ({subs[0]})\", fontsize=10)\n    axes[i].set_ylabel(\"Normalized Value\")\n    axes[i].grid(True)\n\n# Remove empty subplots if any\nfor j in range(num_sensors, len(axes)):\n    fig.delaxes(axes[j])\n\nplt.xlabel(\"Cycle\")\nplt.suptitle(f\"Sensor Trends over Cycles for Engine {sample_engine_id}\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.96])\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:17:34.580444Z","iopub.execute_input":"2025-10-12T09:17:34.58116Z","iopub.status.idle":"2025-10-12T09:17:39.128027Z","shell.execute_reply.started":"2025-10-12T09:17:34.581131Z","shell.execute_reply":"2025-10-12T09:17:39.127167Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Sequence Builder (train and test)","metadata":{}},{"cell_type":"code","source":"# 3. Sequence creation helpers\nSEQ_LEN = 30\n\ndef create_sequences(df, seq_length=SEQ_LEN):\n    X, y = [], []\n    for eid in df['engine_id'].unique():\n        ed = df[df['engine_id']==eid].reset_index(drop=True)\n        for i in range(len(ed)-seq_length):\n            X.append(ed.iloc[i:i+seq_length][feature_cols].values)\n            y.append(ed.iloc[i+seq_length]['RUL'])\n    return np.array(X), np.array(y)\n\ndef create_sequences_test_last(df, seq_length=SEQ_LEN):\n    X, engine_ids = [], []\n    for eid in df['engine_id'].unique():\n        ed = df[df['engine_id']==eid].reset_index(drop=True)\n        if len(ed) >= seq_length:\n            X.append(ed.iloc[-seq_length:][feature_cols].values)\n            engine_ids.append(eid)\n    return np.array(X), np.array(engine_ids)\n\nX, y = create_sequences(train, SEQ_LEN)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\nX_test, test_engine_ids = create_sequences_test_last(test, SEQ_LEN)\ntrue_rul_test = truth['RUL'].values[:len(test_engine_ids)]\nprint('Shapes -', X_train.shape, X_val.shape, X_test.shape)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:18:08.588121Z","iopub.execute_input":"2025-10-12T09:18:08.588589Z","iopub.status.idle":"2025-10-12T09:18:13.987516Z","shell.execute_reply.started":"2025-10-12T09:18:08.588566Z","shell.execute_reply":"2025-10-12T09:18:13.986738Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset & Dataloader","metadata":{}},{"cell_type":"code","source":"# 4. Dataset & dataloader\nclass RUL_Dataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.float32).view(-1,1)\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\nBATCH = 64\ntrain_loader = DataLoader(RUL_Dataset(X_train, y_train), batch_size=BATCH, shuffle=True)\nval_loader = DataLoader(RUL_Dataset(X_val, y_val), batch_size=BATCH, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:18:18.741605Z","iopub.execute_input":"2025-10-12T09:18:18.742099Z","iopub.status.idle":"2025-10-12T09:18:18.806341Z","shell.execute_reply.started":"2025-10-12T09:18:18.742077Z","shell.execute_reply":"2025-10-12T09:18:18.80552Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model definition (parameterize cnn_channels)","metadata":{}},{"cell_type":"code","source":"# 5. Model definition (parameterize cnn_channels)\nclass CNNTransformerModel(nn.Module):\n    def __init__(self, input_dim, cnn_channels=64, d_model=128, nhead=4, num_layers=2, dropout=0.1):\n        super().__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv1d(input_dim, cnn_channels, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv1d(cnn_channels, cnn_channels, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        self.input_proj = nn.Linear(cnn_channels, d_model)\n        self.fc = nn.Sequential(nn.Linear(d_model,64), nn.ReLU(), nn.Dropout(0.2), nn.Linear(64,1))\n\n    def forward(self, x):\n        x = x.permute(0,2,1)  # [B, F, T]\n        x = self.cnn(x)       # [B, C, T]\n        x = x.permute(0,2,1)  # [B, T, C]\n        x = self.input_proj(x)\n        x = self.transformer(x)\n        x = x.mean(dim=1)\n        return self.fc(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:18:22.163692Z","iopub.execute_input":"2025-10-12T09:18:22.163963Z","iopub.status.idle":"2025-10-12T09:18:22.170347Z","shell.execute_reply.started":"2025-10-12T09:18:22.163942Z","shell.execute_reply":"2025-10-12T09:18:22.169624Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Advantages over LSTM/GRU:\n* CNN captures short-term temporal correlations efficiently.\n* Transformer captures long-term dependencies without vanishing gradients.\n* Parallelizable for faster training on GPUs.\n* Better feature extraction from multisensor sequences.","metadata":{}},{"cell_type":"markdown","source":"## Asymmetric loss and metrics","metadata":{}},{"cell_type":"code","source":"# 6. Asymmetric loss and metrics\nmse_loss = nn.MSELoss()\n\ndef asymmetric_loss(pred, true, lambda_over=10.0):\n    base = mse_loss(pred, true)\n    over_pen = torch.relu(pred - true)\n    over_term = (over_pen**2).mean()\n    return base + lambda_over * over_term\n\ndef compute_overestimation_rate(preds, trues):\n    over = (preds - trues) > 0\n    return float(over.sum()) / len(over)\n\n# Modified asymmetric loss to weight by true RUL\ndef weighted_asymmetric_loss(pred, true, lambda_over=10.0, max_rul=125):\n    \"\"\"\n    - Penalizes overestimation (lambda_over)\n    - Gives higher weight to high RUL samples\n    \"\"\"\n    base = mse_loss(pred, true)\n    over_pen = torch.relu(pred - true)\n    over_term = (over_pen**2).mean()\n    \n    # Weight by true RUL (normalized)\n    weight = (true / max_rul).view(-1,1)  # shape [batch_size,1]\n    weighted_base = (weight * (pred - true)**2).mean()\n    \n    return weighted_base + lambda_over * over_term","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:18:26.493991Z","iopub.execute_input":"2025-10-12T09:18:26.494353Z","iopub.status.idle":"2025-10-12T09:18:26.500099Z","shell.execute_reply.started":"2025-10-12T09:18:26.49433Z","shell.execute_reply":"2025-10-12T09:18:26.499463Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* Penalizes overestimation (critical for safety)\n* Can also weight loss by true RUL for more focus on long-lived engines","metadata":{}},{"cell_type":"markdown","source":"# Training & evaluation functions\n* Split training sequences into train/validation sets\n* Use Adam optimizer and early stopping\n* Hyperparameter tuning: learning rate, CNN channels, overestimation penalty","metadata":{"execution":{"iopub.status.busy":"2025-10-12T04:30:37.255507Z","iopub.execute_input":"2025-10-12T04:30:37.256177Z","iopub.status.idle":"2025-10-12T04:30:37.260061Z","shell.execute_reply.started":"2025-10-12T04:30:37.256146Z","shell.execute_reply":"2025-10-12T04:30:37.259193Z"}}},{"cell_type":"code","source":"# 7. Training & evaluation functions\n\ndef train_one_epoch(model, loader, optimizer, lambda_over):\n    model.train()\n    total = 0.0\n    for Xb, yb in loader:\n        Xb, yb = Xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        preds = model(Xb)\n        loss = asymmetric_loss(preds, yb, lambda_over=lambda_over)\n        loss.backward()\n        optimizer.step()\n        total += loss.item() * Xb.size(0)\n    return total / len(loader.dataset)\n\ndef train_one_epoch_weighted(model, loader, optimizer, lambda_over, max_rul=125):\n    model.train()\n    total = 0.0\n    for Xb, yb in loader:\n        Xb, yb = Xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        preds = model(Xb)\n        loss = weighted_asymmetric_loss(preds, yb, lambda_over=lambda_over, max_rul=max_rul)\n        loss.backward()\n        optimizer.step()\n        total += loss.item() * Xb.size(0)\n    return total / len(loader.dataset)\n\n\ndef evaluate(model, loader):\n    model.eval()\n    all_preds, all_trues = [], []\n    with torch.no_grad():\n        for Xb, yb in loader:\n            Xb, yb = Xb.to(device), yb.to(device)\n            preds = model(Xb)\n            all_preds.append(preds.cpu().numpy().flatten())\n            all_trues.append(yb.cpu().numpy().flatten())\n    all_preds = np.concatenate(all_preds)\n    all_trues = np.concatenate(all_trues)\n    val_mse = mean_squared_error(all_trues, all_preds)\n    over_rate = compute_overestimation_rate(all_preds, all_trues)\n    return val_mse, over_rate, all_preds, all_trues\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:18:31.555895Z","iopub.execute_input":"2025-10-12T09:18:31.55616Z","iopub.status.idle":"2025-10-12T09:18:31.563467Z","shell.execute_reply.started":"2025-10-12T09:18:31.556142Z","shell.execute_reply":"2025-10-12T09:18:31.562782Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Hyperparameter grid search","metadata":{}},{"cell_type":"code","source":"# 8. Hyperparameter grid search\nsearch_space = {\n    'lr': [1e-3, 5e-4],\n    'lambda_over': [5.0, 10.0, 20.0],\n    'cnn_channels': [32, 64]\n}\n\nBEST_DIR = 'hp_search_results'\nos.makedirs(BEST_DIR, exist_ok=True)\n\nresults = []\n\nfor lr in search_space['lr']:\n    for lambda_over in search_space['lambda_over']:\n        for cnn_ch in search_space['cnn_channels']:\n            print(f\"Running grid point lr={lr}, lambda_over={lambda_over}, cnn_ch={cnn_ch}\")\n            model = CNNTransformerModel(input_dim=len(feature_cols), cnn_channels=cnn_ch).to(device)\n            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n            EPOCHS = 25\n            best_val_obj = float('inf')\n            patience = 6\n            no_improve = 0\n            for epoch in range(EPOCHS):\n                train_obj = train_one_epoch_weighted(model, train_loader, optimizer, lambda_over)\n                val_mse, val_over, _, _ = evaluate(model, val_loader)\n                # objective combines MSE and over-rate penalty\n                val_obj = val_mse + 1000.0 * val_over\n                print(f\"  Epoch {epoch+1}/{EPOCHS} train_obj={train_obj:.4f} val_mse={val_mse:.4f} val_over={val_over:.3f} val_obj={val_obj:.4f}\")\n                if val_obj < best_val_obj:\n                    best_val_obj = val_obj\n                    torch.save(model.state_dict(), os.path.join(BEST_DIR, f\"best_lr{lr}_lam{lambda_over}_ch{cnn_ch}.pth\"))\n                    no_improve = 0\n                else:\n                    no_improve += 1\n                    if no_improve >= patience:\n                        print(\"  Early stopping\")\n                        break\n            # after training, load best and evaluate\n            model.load_state_dict(torch.load(os.path.join(BEST_DIR, f\"best_lr{lr}_lam{lambda_over}_ch{cnn_ch}.pth\"), map_location=device))\n            val_mse, val_over, val_preds, val_trues = evaluate(model, val_loader)\n            results.append({'lr': lr, 'lambda_over': lambda_over, 'cnn_ch': cnn_ch,\n                            'val_mse': val_mse, 'val_over': val_over, 'val_obj': val_mse + 1000.0*val_over})\n            # save summary CSV per grid point\n            pd.DataFrame(results).to_csv(os.path.join(BEST_DIR, 'grid_search_summary.csv'), index=False)\n\n# print sorted results\nres_df = pd.DataFrame(results).sort_values('val_obj')\nprint('Top grid results:')\nprint(res_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:18:35.76039Z","iopub.execute_input":"2025-10-12T09:18:35.760692Z","iopub.status.idle":"2025-10-12T09:27:26.506751Z","shell.execute_reply.started":"2025-10-12T09:18:35.760671Z","shell.execute_reply":"2025-10-12T09:27:26.50594Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load best hyperparameters & final evaluation on test\n* Metrics:\n    * RMSE: Measures prediction accuracy\n    * Overestimation rate: Fraction of predictions over true RUL","metadata":{}},{"cell_type":"code","source":"# 9. Load best hyperparameters & final evaluation on test\nbest = res_df.iloc[0]\nprint('Selected best config:', best.to_dict())\nbest_model_path = os.path.join(BEST_DIR, f\"best_lr{best['lr']}_lam{best['lambda_over']}_ch{int(best['cnn_ch'])}.pth\")\nmodel = CNNTransformerModel(input_dim=len(feature_cols), cnn_channels=int(best['cnn_ch'])).to(device)\nmodel.load_state_dict(torch.load(best_model_path, map_location=device))\n\n# test predictions\nmodel.eval()\nwith torch.no_grad():\n    X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)\n    y_pred_test = model(X_test_t).cpu().numpy().flatten()\n\nrmse_test = math.sqrt(mean_squared_error(true_rul_test, y_pred_test))\nover_test = compute_overestimation_rate(y_pred_test, true_rul_test)\nprint(f\"Final Test RMSE: {rmse_test:.3f}  Overestimation rate: {over_test*100:.2f}%\")\n\nresults_df = pd.DataFrame({'engine_id': test_engine_ids, 'true_RUL': true_rul_test, 'predicted_RUL': y_pred_test})\nresults_df['error'] = results_df['predicted_RUL'] - results_df['true_RUL']\nresults_df.to_csv('final_predictions.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:30:03.100456Z","iopub.execute_input":"2025-10-12T09:30:03.100764Z","iopub.status.idle":"2025-10-12T09:30:03.143288Z","shell.execute_reply.started":"2025-10-12T09:30:03.100743Z","shell.execute_reply":"2025-10-12T09:30:03.142607Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Attribution (SmoothGrad Grad x Input) and mapping to subsystems","metadata":{}},{"cell_type":"code","source":"# 10. Attribution (SmoothGrad Grad x Input) and mapping to subsystems\n\ndef compute_grad_times_input_smooth_single(model, x_np, n_samples=12, stdev=1e-3):\n    model.eval()\n    X = torch.tensor(x_np, dtype=torch.float32).unsqueeze(0).to(device)\n    accum = np.zeros_like(x_np)\n    for _ in range(n_samples):\n        noise = torch.randn_like(X) * stdev\n        Xn = (X + noise).clone().detach().requires_grad_(True)\n        out = model(Xn)\n        out.sum().backward()\n        grads = Xn.grad.detach().cpu().numpy()[0]\n        inputs = Xn.detach().cpu().numpy()[0]\n        accum += np.abs(grads * inputs)\n    return accum / n_samples\n\nreports = []\nTHRESHOLD_RUL_FLAG = 30\nfor i, (eid, pred, true_rul) in enumerate(zip(test_engine_ids, y_pred_test, true_rul_test)):\n    attr_map = compute_grad_times_input_smooth_single(model, X_test[i])  # [seq_len, features]\n    feat_imp = attr_map.sum(axis=0)\n    feat_imp_norm = feat_imp / (feat_imp.sum() + 1e-12)\n    top_idx = feat_imp_norm.argsort()[::-1][:5]\n    top_sensors = [(feature_cols[idx], float(feat_imp_norm[idx])) for idx in top_idx]\n    # map sensors to subsystems and aggregate\n    subsystem_scores = {}\n    for idx in range(len(feature_cols)):\n        sname = feature_cols[idx]\n        sensor_key = sname  # e.g., 'sensor_1'\n        subs = SENSOR_TO_SUBSYSTEM.get(sensor_key, ['Unknown'])\n        for sub in subs:\n            subsystem_scores[sub] = subsystem_scores.get(sub, 0.0) + float(feat_imp_norm[idx])\n    # sort subsystems\n    subs_sorted = sorted(subsystem_scores.items(), key=lambda x: x[1], reverse=True)\n    imminent = bool(pred <= THRESHOLD_RUL_FLAG)\n    reports.append({\n        'engine_id': int(eid),\n        'predicted_RUL': float(pred),\n        'true_RUL': int(true_rul),\n        'imminent_failure_flag': imminent,\n        'top_sensors': top_sensors,\n        'top_subsystems': subs_sorted[:5]\n    })\n\nreports_df = pd.DataFrame(reports)\nreports_df.to_csv('engine_failure_reports.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:30:08.12786Z","iopub.execute_input":"2025-10-12T09:30:08.128123Z","iopub.status.idle":"2025-10-12T09:30:14.456528Z","shell.execute_reply.started":"2025-10-12T09:30:08.128104Z","shell.execute_reply":"2025-10-12T09:30:14.455691Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reports_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:30:40.093673Z","iopub.execute_input":"2025-10-12T09:30:40.094246Z","iopub.status.idle":"2025-10-12T09:30:40.112166Z","shell.execute_reply.started":"2025-10-12T09:30:40.094216Z","shell.execute_reply":"2025-10-12T09:30:40.111618Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Results Visualization\n* Predicted vs True RUL Scatter\n* Error distribution\n* Top contributing sensors/subsystems","metadata":{}},{"cell_type":"code","source":"# === 12. Visualization for LinkedIn / Reports ===\n\nimport seaborn as sns\nsns.set(style=\"whitegrid\", font_scale=1.1)\n\n# 12.1 True vs Predicted RUL for test engines\nplt.figure(figsize=(10,6))\nplt.scatter(results_df['true_RUL'], results_df['predicted_RUL'], c='blue', alpha=0.6)\nplt.plot([0, MAX_RUL],[0, MAX_RUL], 'r--', label='Ideal')\nplt.xlabel(\"True RUL (cycles)\")\nplt.ylabel(\"Predicted RUL (cycles)\")\nplt.title(\"Predicted vs True RUL for Test Engines\")\nplt.legend()\nplt.tight_layout()\nplt.savefig(\"pred_vs_true_rul.png\", dpi=150)\nplt.show()\n\n\n# 12.2 Error distribution across test engines\nplt.figure(figsize=(10,5))\nsns.histplot(results_df['error'], bins=20, kde=True, color='orange')\nplt.axvline(0, color='black', linestyle='--')\nplt.xlabel(\"Prediction Error (Predicted - True RUL)\")\nplt.ylabel(\"Count\")\nplt.title(\"Distribution of RUL Prediction Errors\")\nplt.tight_layout()\nplt.savefig(\"rul_error_distribution.png\", dpi=150)\nplt.show()\n\n\n# 12.3 Feature importance (averaged across all engines)\navg_feat_imp = np.zeros(len(feature_cols))\nfor i in range(len(X_test)):\n    attr_map = compute_grad_times_input_smooth_single(model, X_test[i])\n    avg_feat_imp += attr_map.sum(axis=0)\navg_feat_imp /= len(X_test)\navg_feat_imp_norm = avg_feat_imp / (avg_feat_imp.sum() + 1e-12)\n\nfeat_imp_df = pd.DataFrame({\n    'feature': feature_cols,\n    'importance': avg_feat_imp_norm\n}).sort_values('importance', ascending=False)\n\nplt.figure(figsize=(12,6))\nsns.barplot(data=feat_imp_df, x='feature', y='importance', palette=\"viridis\")\nplt.xticks(rotation=45, ha='right')\nplt.title(\"Feature Importance (SmoothGrad x Input, averaged over test engines)\")\nplt.tight_layout()\nplt.savefig(\"feature_importance.png\", dpi=150)\nplt.show()\n\n\n# 12.4 Subsystem importance (aggregated over engines)\nsubsystem_scores = {}\nfor i in range(len(X_test)):\n    attr_map = compute_grad_times_input_smooth_single(model, X_test[i])\n    feat_imp = attr_map.sum(axis=0)\n    feat_imp_norm = feat_imp / (feat_imp.sum() + 1e-12)\n    for idx, sensor_key in enumerate(feature_cols):\n        subs = SENSOR_TO_SUBSYSTEM.get(sensor_key, ['Unknown'])\n        for sub in subs:\n            subsystem_scores[sub] = subsystem_scores.get(sub, 0) + feat_imp_norm[idx]\n\nsubsystem_df = pd.DataFrame(list(subsystem_scores.items()), columns=['subsystem','importance']).sort_values('importance', ascending=False)\n\nplt.figure(figsize=(10,5))\nsns.barplot(data=subsystem_df, x='subsystem', y='importance', palette='magma')\nplt.xticks(rotation=45, ha='right')\nplt.title(\"Subsystem Importance (Aggregated from sensor attributions)\")\nplt.tight_layout()\nplt.savefig(\"subsystem_importance.png\", dpi=150)\nplt.show()\n\n# Line Graph: Predicted vs True RUL ===\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12,6))\nplt.plot(test_engine_ids, true_rul_test, label='True RUL', marker='o', linestyle='-', color='blue')\nplt.plot(test_engine_ids, y_pred_test, label='Predicted RUL', marker='x', linestyle='--', color='red')\nplt.xlabel(\"Engine ID\")\nplt.ylabel(\"Remaining Useful Life (cycles)\")\nplt.title(\"Predicted vs True RUL for Test Engines\")\nplt.legend()\nplt.xticks(rotation=45)\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(\"linegraph_pred_vs_true_rul.png\", dpi=150)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-10-12T09:31:02.755694Z","iopub.execute_input":"2025-10-12T09:31:02.755971Z","iopub.status.idle":"2025-10-12T09:31:18.517856Z","shell.execute_reply.started":"2025-10-12T09:31:02.75595Z","shell.execute_reply":"2025-10-12T09:31:18.516957Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Generate templated maintenance reports for imminent engines\n* Highlight top sensors indicating degradation\n* Identify subsystems likely to fail\n* Provide inspection recommendations based on predicted RUL\\\nOptional: Generate professional reports using a local LLM","metadata":{}},{"cell_type":"code","source":"# 11. Generate templated maintenance reports for imminent engines (save all, print one)\n\ndef generate_template_report(entry):\n    eid = entry['engine_id']\n    pred = entry['predicted_RUL']\n    true_rul = entry['true_RUL']\n    sensors = entry['top_sensors']\n    subs = entry['top_subsystems']\n    s_text = ', '.join([f\"{name} ({weight:.2f})\" for name, weight in sensors])\n    subs_text = ', '.join([f\"{name} ({weight:.2f})\" for name, weight in subs])\n    lines = [\n        f\"Engine ID: {eid}\",\n        f\"Predicted remaining life: {pred:.1f} cycles (true RUL: {true_rul})\",\n        f\"Top sensors indicating degradation: {s_text}\",\n        f\"Likely affected subsystems: {subs_text}\",\n        \"\",\n        \"Maintenance recommendation:\",\n        \"- Inspect subsystems listed above and their sensor harnesses/fixtures.\",\n        \"- For temperature sensors: check for thermocouple drift, insulation, fuel/air mixing anomalies.\",\n        \"- For pressure sensors: check for leaks, blockages, or compressor stalls.\",\n        \"- For vibration/rotational sensors: inspect bearings, couplings, and mounts.\",\n        \"- If sensor replacement is performed, recalibrate and run diagnostic cycles; re-evaluate RUL.\",\n        \"- Consider immediate grounding if predicted RUL <= 10 cycles until inspection completes.\"\n    ]\n    return \"\\n\".join(lines)\n\nimminent = [r for r in reports if r['imminent_failure_flag']]\n\nif imminent:\n    # Print the first imminent report\n    print(\"===== Maintenance Report (First Imminent Engine) =====\")\n    print(generate_template_report(imminent[0]))\n    \n    # Save all imminent engine reports to files\n    for r in imminent:\n        txt = generate_template_report(r)\n        fname = f\"engine_{r['engine_id']}_maintenance_report.txt\"\n        with open(fname, 'w') as f:\n            f.write(txt)\nelse:\n    print(\"No imminent engines flagged for maintenance.\")\n\nprint('Saved final outputs: final_predictions.csv, engine_failure_reports.csv, engine_*_maintenance_report.txt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:31:36.257679Z","iopub.execute_input":"2025-10-12T09:31:36.258157Z","iopub.status.idle":"2025-10-12T09:31:36.266879Z","shell.execute_reply.started":"2025-10-12T09:31:36.258135Z","shell.execute_reply":"2025-10-12T09:31:36.266225Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Optional: LLM rephrasing using HuggingFace","metadata":{}},{"cell_type":"code","source":"# 11. Generate maintenance reports using a local LLM (from Kaggle input)\n'''\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\n\n# Path to the model in Kaggle input\nmodel_name = \"/kaggle/input/qwen2.5/transformers/0.5b/1\"\n\n# Load tokenizer and model\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef generate_llm_report(entry, max_new_tokens=300):\n    eid = entry['engine_id']\n    pred = entry['predicted_RUL']\n    true_rul = entry['true_RUL']\n    sensors = entry['top_sensors']\n    subs = entry['top_subsystems']\n    \n    s_text = ', '.join([f\"{name} ({weight:.2f})\" for name, weight in sensors])\n    subs_text = ', '.join([f\"{name} ({weight:.2f})\" for name, weight in subs])\n    \n    prompt = f\"\"\"\nYou are an aircraft maintenance expert. Generate a professional maintenance report for this engine:\n\nEngine ID: {eid}\nPredicted RUL: {pred:.1f} cycles\nTrue RUL: {true_rul}\nTop sensors indicating degradation: {s_text}\nLikely affected subsystems: {subs_text}\n\nProvide detailed recommendations, including inspections, sensor checks, subsystem replacements if needed, safety measures, and urgency based on RUL.\n\"\"\"\n\n    # Tokenize and generate text\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n    output_ids = model.generate(\n        **inputs,\n        max_new_tokens=max_new_tokens,\n        temperature=0.2,\n        do_sample=False\n    )\n    llm_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n\n    report_lines = [\n        f\"Engine ID: {eid}\",\n        f\"Predicted remaining life: {pred:.1f} cycles (true RUL: {true_rul})\",\n        f\"Top sensors indicating degradation: {s_text}\",\n        f\"Likely affected subsystems: {subs_text}\",\n        \"\",\n        \"Maintenance Recommendation (LLM-generated):\",\n        llm_text\n    ]\n    return \"\\n\".join(report_lines)\n\n# Generate reports for imminent failures\nimminent = [r for r in reports if r['imminent_failure_flag']]\nfor r in imminent:\n    txt = generate_llm_report(r)\n    fname = f\"engine_{r['engine_id']}_maintenance_llm_report.txt\"\n    with open(fname, 'w') as f:\n        f.write(txt)\n\nprint('Saved final outputs: final_predictions.csv, engine_failure_reports.csv, engine_*_maintenance_report.txt')\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:13:00.580951Z","iopub.status.idle":"2025-10-12T09:13:00.581244Z","shell.execute_reply.started":"2025-10-12T09:13:00.581093Z","shell.execute_reply":"2025-10-12T09:13:00.581105Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion\n* CNN-Transformer outperforms classical LSTM/GRU on long sequences.\n* Asymmetric loss prevents overestimation, enhancing safety.\n* SmoothGrad attribution provides actionable insights for maintenance teams.\n* Combined with LLM-generated reports, this pipeline bridges predictive analytics and maintenance decision support.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}